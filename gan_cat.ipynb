{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0d3773b654528d79880d3e2b33a682f0f55f4d8370c8ead39985baabf4eb4f1db",
   "display_name": "Python 3.8.8 64-bit ('test': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import spectral_norm as SN\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "0   0      0      0      0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1   1      0      1      0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2   2      0      0      0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3   3      0      1      0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4   4      0      0      0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "   ...      nom_9 ord_0        ord_1        ord_2 ord_3 ord_4  ord_5 day  \\\n",
       "0  ...  2f4cb3d51     2  Grandmaster         Cold     h     D     kr   2   \n",
       "1  ...  f83c56c21     1  Grandmaster          Hot     a     A     bF   7   \n",
       "2  ...  ae6800dd0     1       Expert     Lava Hot     h     R     Jc   7   \n",
       "3  ...  8270f0d71     1  Grandmaster  Boiling Hot     i     D     kW   2   \n",
       "4  ...  b164b72a7     1  Grandmaster     Freezing     a     R     qP   7   \n",
       "\n",
       "  month target  \n",
       "0     2      0  \n",
       "1     8      0  \n",
       "2     2      0  \n",
       "3     1      1  \n",
       "4     8      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>nom_0</th>\n      <th>nom_1</th>\n      <th>nom_2</th>\n      <th>nom_3</th>\n      <th>...</th>\n      <th>nom_9</th>\n      <th>ord_0</th>\n      <th>ord_1</th>\n      <th>ord_2</th>\n      <th>ord_3</th>\n      <th>ord_4</th>\n      <th>ord_5</th>\n      <th>day</th>\n      <th>month</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>Green</td>\n      <td>Triangle</td>\n      <td>Snake</td>\n      <td>Finland</td>\n      <td>...</td>\n      <td>2f4cb3d51</td>\n      <td>2</td>\n      <td>Grandmaster</td>\n      <td>Cold</td>\n      <td>h</td>\n      <td>D</td>\n      <td>kr</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>Green</td>\n      <td>Trapezoid</td>\n      <td>Hamster</td>\n      <td>Russia</td>\n      <td>...</td>\n      <td>f83c56c21</td>\n      <td>1</td>\n      <td>Grandmaster</td>\n      <td>Hot</td>\n      <td>a</td>\n      <td>A</td>\n      <td>bF</td>\n      <td>7</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>Blue</td>\n      <td>Trapezoid</td>\n      <td>Lion</td>\n      <td>Russia</td>\n      <td>...</td>\n      <td>ae6800dd0</td>\n      <td>1</td>\n      <td>Expert</td>\n      <td>Lava Hot</td>\n      <td>h</td>\n      <td>R</td>\n      <td>Jc</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>Red</td>\n      <td>Trapezoid</td>\n      <td>Snake</td>\n      <td>Canada</td>\n      <td>...</td>\n      <td>8270f0d71</td>\n      <td>1</td>\n      <td>Grandmaster</td>\n      <td>Boiling Hot</td>\n      <td>i</td>\n      <td>D</td>\n      <td>kW</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Red</td>\n      <td>Trapezoid</td>\n      <td>Lion</td>\n      <td>Canada</td>\n      <td>...</td>\n      <td>b164b72a7</td>\n      <td>1</td>\n      <td>Grandmaster</td>\n      <td>Freezing</td>\n      <td>a</td>\n      <td>R</td>\n      <td>qP</td>\n      <td>7</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/only_cat/train.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"id\", \"target\"],axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(regex=\"bin|month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[[\"bin_4\",\"bin_3\"]] ## fac_col 변수 순서대로 생성됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bin_0 2\nbin_1 2\nbin_2 2\nbin_3 2\nbin_4 2\nmonth 12\n"
     ]
    }
   ],
   "source": [
    "fac_cols = data.columns.tolist()\n",
    "for col in fac_cols :\n",
    "    print(col , len(data[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/envs/test/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        bin_0  bin_1  bin_2 bin_3 bin_4  month\n",
       "0           0      0      0     T     Y      2\n",
       "1           0      1      0     T     Y      8\n",
       "2           0      0      0     F     Y      2\n",
       "3           0      1      0     F     Y      1\n",
       "4           0      0      0     F     N      8\n",
       "...       ...    ...    ...   ...   ...    ...\n",
       "299995      0      0      0     T     N      8\n",
       "299996      0      0      0     F     Y      2\n",
       "299997      0      0      0     F     Y      9\n",
       "299998      0      1      0     F     Y      8\n",
       "299999      0      0      0     F     Y      3\n",
       "\n",
       "[300000 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>N</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>T</td>\n      <td>N</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "encoder = ce.OneHotEncoder(cols=fac_cols, use_cat_names= True ,handle_unknown=\"ignore\",)\n",
    "encoder.fit(data)\n",
    "data_trans = encoder.transform(data)\n",
    "encoder.inverse_transform(data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans_np = data_trans.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans_tensor = torch.FloatTensor(data_trans_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "map_info = deepcopy(encoder.category_mapping)\n",
    "[_dict_.update({\"len\" : len(_dict_[\"mapping\"])-1}) for _dict_ in map_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import gumbel_softmax as g_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit2onehot(logit, map_info) :\n",
    "    cur_position = 0\n",
    "    result = []\n",
    "    for col_info in map_info :\n",
    "        cur_position += col_info[\"len\"]\n",
    "        tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "        onehot_ = g_softmax(logits= tt , hard=True,tau=1)\n",
    "        result.append(onehot_)\n",
    "    return torch.cat(result,axis=1)\n",
    "\n",
    "from torch.distributions import Categorical\n",
    "def logit2dist(logit,map_info) :\n",
    "    cur_position = 0\n",
    "    result = []\n",
    "    for col_info in map_info :\n",
    "        cur_position += col_info[\"len\"]\n",
    "        tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "        dist = Categorical(logits = tt)\n",
    "        result.append(dist)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "2\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "2\n",
      "tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "2\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "2\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "12\n",
      "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "cur_position = 0\n",
    "for col_info in map_info :\n",
    "    print(col_info[\"len\"])\n",
    "    cur_position += col_info[\"len\"]\n",
    "    tt = data_trans_tensor[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "    print(g_softmax(logits= tt , hard=True,tau=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_column = data_trans.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataModule(pl.LightningDataModule) :\n",
    "    def __init__(self, data , batch_size:int = 32 , num_workers:int=3) :\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.dims = self.data.shape[1]\n",
    "    \n",
    "    def prepare_data(self,) :\n",
    "        pass\n",
    "\n",
    "    def setup(self,stage=None) :\n",
    "        if stage == \"fit\" or state is None :\n",
    "            train_length = int(len(self.data)*0.8)\n",
    "            lengths = [train_length, int(len(self.data)-train_length)]\n",
    "            self.train, self.val = random_split(self.data, lengths)\n",
    "        \n",
    "        if stage == \"test\" or stage is None :\n",
    "            self.test = self.data   \n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train , batch_size= self.batch_size , num_workers=self.num_workers )\n",
    "\n",
    "    def valid_dataloader(self):\n",
    "        return DataLoader(self.val , batch_size= self.batch_size , num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test , batch_size= self.batch_size , num_workers=self.num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, out_shape, map_info , encoder, total_column):\n",
    "        super().__init__()\n",
    "        self.out_shape = out_shape\n",
    "        self.map_info = map_info\n",
    "        self.encoder = encoder\n",
    "        self.total_column = total_column\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=True),\n",
    "            *block(128, 128, normalize=True),\n",
    "            *block(128, 64, normalize=True),\n",
    "            *block(64, 32, normalize=True),\n",
    "            nn.Linear(32, self.out_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.model(z)\n",
    "        # img = img.view(img.size(0), *self.out_shape)\n",
    "        return x\n",
    "\n",
    "    def inference(self,z) :\n",
    "        x = self.model(z)\n",
    "        x = self.logit2onehot(x)\n",
    "        return self.onehot2rev(x)\n",
    "\n",
    "    def splitbycolumn(self,z) :\n",
    "        logit = self.model(z)\n",
    "        cur_position = 0\n",
    "        result = []\n",
    "        for col_info in self.map_info :\n",
    "            cur_position += col_info[\"len\"]\n",
    "            tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "            result.append(tt)\n",
    "        return result\n",
    "\n",
    "    def logit2onehot(self,logit) :\n",
    "        cur_position = 0\n",
    "        result = []\n",
    "        for col_info in self.map_info :\n",
    "            cur_position += col_info[\"len\"]\n",
    "            tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "            onehot_ = g_softmax(logits= tt , hard=True,tau=1)\n",
    "            result.append(onehot_)\n",
    "        return torch.cat(result,axis=1)\n",
    "    \n",
    "    def logit2dist(self,logit) :\n",
    "        cur_position = 0\n",
    "        result = []\n",
    "        for col_info in self.map_info :\n",
    "            cur_position += col_info[\"len\"]\n",
    "            tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "            dist = Categorical(logits = tt)\n",
    "            result.append(dist)\n",
    "        return result\n",
    "\n",
    "    def onehot2rev(self,tensor) :\n",
    "        gene_onehot_pd = pd.DataFrame(tensor.detach().numpy(),\n",
    "        columns=self.total_column)\n",
    "        gene_data = self.encoder.inverse_transform(gene_onehot_pd)\n",
    "        return gene_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim=30, out_shape=len(total_column),\n",
    "map_info=map_info,encoder=encoder , total_column=total_column)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    bin_0  bin_1  bin_2 bin_3 bin_4  month\n",
       "0       0      1      1     T     Y      6\n",
       "1       1      1      0     F     Y      8\n",
       "2       0      1      1     F     Y      7\n",
       "3       0      0      0     F     Y     12\n",
       "4       1      1      0     T     Y      8\n",
       "..    ...    ...    ...   ...   ...    ...\n",
       "95      1      0      0     F     N      1\n",
       "96      0      0      1     F     Y      3\n",
       "97      0      1      1     T     Y      5\n",
       "98      0      1      1     T     N      4\n",
       "99      0      0      1     F     N      8\n",
       "\n",
       "[100 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>N</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>T</td>\n      <td>N</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>F</td>\n      <td>N</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "z = torch.randn(100, 30)\n",
    "gene_logit = generator(z)\n",
    "gene_onehot_tensor = logit2onehot(gene_logit, map_info)\n",
    "gene_onehot_pd = pd.DataFrame(gene_onehot_tensor.detach().numpy(),columns=total_column)\n",
    "gene_data = encoder.inverse_transform(gene_onehot_pd)\n",
    "gene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(100, 30)\n",
    "# generator.inference(z)\n",
    "# generator.splitbycolumn(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor(0.6840, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6928, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6880, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6877, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6926, grad_fn=<MeanBackward0>),\n",
       " tensor(2.4769, grad_fn=<MeanBackward0>)]"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "[dist.entropy().mean() for dist in logit2dist(gene_logit , map_info)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, out_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(out_shape, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, out):\n",
    "        validity = self.model(out)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule): \n",
    "    def __init__(self,\n",
    "                input_dim = None,\n",
    "                latent_dim =100 , \n",
    "                lr: float = 0.0002,\n",
    "                b1: float = 0.5,\n",
    "                b2: float = 0.999,\n",
    "                generator_parm:dict={},\n",
    "                discriminator_parm:dict={},\n",
    "                batch_size: int = 64,\n",
    "                **kwargs) :\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim,\n",
    "        out_shape=self.hparams.input_dim,**generator_parm)\n",
    "\n",
    "        self.discriminator = Discriminator(out_shape=self.hparams.input_dim,**discriminator_parm)\n",
    "\n",
    "        self.validation_z = torch.randn(8, self.hparams.latent_dim)\n",
    "\n",
    "        self.example_input_array = torch.zeros(2, self.hparams.latent_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "    \n",
    "    def inference(self,z) :\n",
    "        return self.generator.inference(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        x = batch\n",
    "        # sample noise\n",
    "        z = torch.randn(x.shape[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(x)\n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "\n",
    "            # generate images\n",
    "            self.generated_imgs = self(z)\n",
    "\n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            valid = torch.ones(x.size(0), 1)\n",
    "            valid = valid.type_as(x)\n",
    "\n",
    "            # adversarial loss is binary cross-entropy\n",
    "            g_loss = self.adversarial_loss(self.discriminator(self(z)), valid)\n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': g_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(x.size(0), 1)\n",
    "            valid = valid.type_as(x)\n",
    "\n",
    "            real_loss = self.adversarial_loss(self.discriminator(x), valid)\n",
    "\n",
    "            # how well can it label as fake?\n",
    "            fake = torch.zeros(x.size(0), 1)\n",
    "            fake = fake.type_as(x)\n",
    "\n",
    "            fake_loss = self.adversarial_loss(\n",
    "                self.discriminator(self(z).detach()), fake)\n",
    "\n",
    "            # discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2\n",
    "\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        z = self.validation_z.type_as(self.generator.model[0].weight)\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_parm = dict(map_info=map_info,encoder=encoder,total_column = total_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "data_trans_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name          | Type          | Params | In sizes | Out sizes\n",
      "-----------------------------------------------------------------------\n",
      "0 | generator     | Generator     | 41.2 K | [2, 100] | [2, 22]  \n",
      "1 | discriminator | Discriminator | 143 K  | ?        | ?        \n",
      "-----------------------------------------------------------------------\n",
      "184 K     Trainable params\n",
      "0         Non-trainable params\n",
      "184 K     Total params\n",
      "0.738     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92d8a286c1dd4374998014b0ad616a8c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dm = TabularDataModule(data_trans_np.astype(np.float32))\n",
    "model = GAN(dm.size(), generator_parm = generator_parm)\n",
    "trainer = pl.Trainer(gpus=0, max_epochs=5, progress_bar_refresh_rate=20)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   bin_0  bin_1  bin_2 bin_3 bin_4  month\n",
       "0      0      0      1     F     Y      9\n",
       "1      0      0      1     F     N      7\n",
       "2      1      0      0     F     Y      8\n",
       "3      0      0      1     F     Y      9\n",
       "4      0      0      1     T     N      9\n",
       "5      1      0      0     F     Y      2\n",
       "6      0      0      0     T     Y      1\n",
       "7      0      0      1     F     Y      8\n",
       "8      1      0      1     T     Y      8\n",
       "9      0      0      1     T     N      5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>F</td>\n      <td>N</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>T</td>\n      <td>N</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>T</td>\n      <td>N</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "z = torch.randn(10, model.hparams.latent_dim)\n",
    "model.inference(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}