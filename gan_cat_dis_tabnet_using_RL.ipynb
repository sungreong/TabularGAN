{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0d3773b654528d79880d3e2b33a682f0f55f4d8370c8ead39985baabf4eb4f1db",
   "display_name": "Python 3.8.8 64-bit ('test': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Generator\n",
    "* Feature \n",
    "    * Architecture : Any\n",
    "    * 역변환을 통해서 실제값 만들기\n",
    "\n",
    "# Discriminator\n",
    "* Feature \n",
    "    * Architecture : TABNET\n",
    "    * 전처리 되지 않은 데이터를 바로 사용하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import spectral_norm as SN\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"TABNET_simple\")\n",
    "from tab_network import TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "0   0      0      0      0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1   1      0      1      0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2   2      0      0      0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3   3      0      1      0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4   4      0      0      0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "   ...      nom_9 ord_0        ord_1        ord_2 ord_3 ord_4  ord_5 day  \\\n",
       "0  ...  2f4cb3d51     2  Grandmaster         Cold     h     D     kr   2   \n",
       "1  ...  f83c56c21     1  Grandmaster          Hot     a     A     bF   7   \n",
       "2  ...  ae6800dd0     1       Expert     Lava Hot     h     R     Jc   7   \n",
       "3  ...  8270f0d71     1  Grandmaster  Boiling Hot     i     D     kW   2   \n",
       "4  ...  b164b72a7     1  Grandmaster     Freezing     a     R     qP   7   \n",
       "\n",
       "  month target  \n",
       "0     2      0  \n",
       "1     8      0  \n",
       "2     2      0  \n",
       "3     1      1  \n",
       "4     8      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>nom_0</th>\n      <th>nom_1</th>\n      <th>nom_2</th>\n      <th>nom_3</th>\n      <th>...</th>\n      <th>nom_9</th>\n      <th>ord_0</th>\n      <th>ord_1</th>\n      <th>ord_2</th>\n      <th>ord_3</th>\n      <th>ord_4</th>\n      <th>ord_5</th>\n      <th>day</th>\n      <th>month</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>Green</td>\n      <td>Triangle</td>\n      <td>Snake</td>\n      <td>Finland</td>\n      <td>...</td>\n      <td>2f4cb3d51</td>\n      <td>2</td>\n      <td>Grandmaster</td>\n      <td>Cold</td>\n      <td>h</td>\n      <td>D</td>\n      <td>kr</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>Green</td>\n      <td>Trapezoid</td>\n      <td>Hamster</td>\n      <td>Russia</td>\n      <td>...</td>\n      <td>f83c56c21</td>\n      <td>1</td>\n      <td>Grandmaster</td>\n      <td>Hot</td>\n      <td>a</td>\n      <td>A</td>\n      <td>bF</td>\n      <td>7</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>Blue</td>\n      <td>Trapezoid</td>\n      <td>Lion</td>\n      <td>Russia</td>\n      <td>...</td>\n      <td>ae6800dd0</td>\n      <td>1</td>\n      <td>Expert</td>\n      <td>Lava Hot</td>\n      <td>h</td>\n      <td>R</td>\n      <td>Jc</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>Red</td>\n      <td>Trapezoid</td>\n      <td>Snake</td>\n      <td>Canada</td>\n      <td>...</td>\n      <td>8270f0d71</td>\n      <td>1</td>\n      <td>Grandmaster</td>\n      <td>Boiling Hot</td>\n      <td>i</td>\n      <td>D</td>\n      <td>kW</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Red</td>\n      <td>Trapezoid</td>\n      <td>Lion</td>\n      <td>Canada</td>\n      <td>...</td>\n      <td>b164b72a7</td>\n      <td>1</td>\n      <td>Grandmaster</td>\n      <td>Freezing</td>\n      <td>a</td>\n      <td>R</td>\n      <td>qP</td>\n      <td>7</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/only_cat/train.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"id\", \"target\"],axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.filter(regex=\"bin|month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/envs/test/lib/python3.8/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "fac_cols = df.columns.tolist()\n",
    "num_cols = []\n",
    "df[fac_cols] = df[fac_cols].astype(\"object\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-7-64552185dea0>:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[col] = df[col].fillna(\"VV_likely\")\n<ipython-input-7-64552185dea0>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[col] = l_enc.fit_transform(df[col].values)\n"
     ]
    }
   ],
   "source": [
    "types = df.dtypes\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in fac_cols  + num_cols :\n",
    "    if types[col] == 'object' :\n",
    "        l_enc = LabelEncoder()\n",
    "        df[col] = df[col].fillna(\"VV_likely\")\n",
    "        df[col] = l_enc.fit_transform(df[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        df.fillna(df.loc[:, col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ col for col in df.columns if col in fac_cols + num_cols] \n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(features)\n",
    "output_dim = 1\n",
    "from typing import List, Any, Dict\n",
    "import torch\n",
    "n_d: int = 5\n",
    "n_a: int = 5\n",
    "n_steps: int = 5\n",
    "gamma: float = 1.3\n",
    "cat_idxs: List[int] =[]\n",
    "cat_dims: List[int] =[]\n",
    "cat_emb_dim: int = 3\n",
    "n_independent: int = 2\n",
    "n_shared: int = 3\n",
    "epsilon: float = 1e-15\n",
    "momentum: float = 0.02\n",
    "lambda_sparse: float = 1e-3\n",
    "seed: int = 2345\n",
    "clip_value: int = 1\n",
    "verbose: int = 1\n",
    "optimizer_fn: Any = torch.optim.Adam\n",
    "optimizer_params: Dict = dict(lr=2e-2)\n",
    "scheduler_fn: Any = None\n",
    "scheduler_params: Dict = {\"step_size\":50,\"gamma\":0.9}\n",
    "mask_type: str = \"entmax\" # \"sparsemax\"\n",
    "input_dim: int = input_dim\n",
    "output_dim: int = output_dim\n",
    "device_name: str = \"auto\"\n",
    "virtual_batch_size=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   bin_0  bin_1  bin_2  bin_3  bin_4  month\n",
       "0      0      0      0      1      1      1\n",
       "1      0      1      0      1      1      7\n",
       "2      0      0      0      0      1      1\n",
       "3      0      1      0      0      1      0\n",
       "4      0      0      0      0      0      7"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import category_encoders as ce \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/envs/test/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        bin_0  bin_1  bin_2  bin_3  bin_4  month\n",
       "0           0      0      0      1      1      1\n",
       "1           0      1      0      1      1      7\n",
       "2           0      0      0      0      1      1\n",
       "3           0      1      0      0      1      0\n",
       "4           0      0      0      0      0      7\n",
       "...       ...    ...    ...    ...    ...    ...\n",
       "299995      0      0      0      1      0      7\n",
       "299996      0      0      0      0      1      1\n",
       "299997      0      0      0      0      1      8\n",
       "299998      0      1      0      0      1      7\n",
       "299999      0      0      0      0      1      2\n",
       "\n",
       "[300000 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "encoder = ce.OneHotEncoder(cols=fac_cols, use_cat_names= True ,handle_unknown=\"ignore\",)\n",
    "encoder.fit(df)\n",
    "df_trans = encoder.transform(df)\n",
    "encoder.inverse_transform(df_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        bin_0_0.0  bin_0_1.0  bin_1_0.0  bin_1_1.0  bin_2_0.0  bin_2_1.0  \\\n",
       "0               1          0          1          0          1          0   \n",
       "1               1          0          0          1          1          0   \n",
       "2               1          0          1          0          1          0   \n",
       "3               1          0          0          1          1          0   \n",
       "4               1          0          1          0          1          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "299995          1          0          1          0          1          0   \n",
       "299996          1          0          1          0          1          0   \n",
       "299997          1          0          1          0          1          0   \n",
       "299998          1          0          0          1          1          0   \n",
       "299999          1          0          1          0          1          0   \n",
       "\n",
       "        bin_3_1.0  bin_3_0.0  bin_4_1.0  bin_4_0.0  ...  month_0.0  month_3.0  \\\n",
       "0               1          0          1          0  ...          0          0   \n",
       "1               1          0          1          0  ...          0          0   \n",
       "2               0          1          1          0  ...          0          0   \n",
       "3               0          1          1          0  ...          1          0   \n",
       "4               0          1          0          1  ...          0          0   \n",
       "...           ...        ...        ...        ...  ...        ...        ...   \n",
       "299995          1          0          0          1  ...          0          0   \n",
       "299996          0          1          1          0  ...          0          0   \n",
       "299997          0          1          1          0  ...          0          0   \n",
       "299998          0          1          1          0  ...          0          0   \n",
       "299999          0          1          1          0  ...          0          0   \n",
       "\n",
       "        month_9.0  month_2.0  month_6.0  month_8.0  month_11.0  month_10.0  \\\n",
       "0               0          0          0          0           0           0   \n",
       "1               0          0          0          0           0           0   \n",
       "2               0          0          0          0           0           0   \n",
       "3               0          0          0          0           0           0   \n",
       "4               0          0          0          0           0           0   \n",
       "...           ...        ...        ...        ...         ...         ...   \n",
       "299995          0          0          0          0           0           0   \n",
       "299996          0          0          0          0           0           0   \n",
       "299997          0          0          0          1           0           0   \n",
       "299998          0          0          0          0           0           0   \n",
       "299999          0          1          0          0           0           0   \n",
       "\n",
       "        month_4.0  month_5.0  \n",
       "0               0          0  \n",
       "1               0          0  \n",
       "2               0          0  \n",
       "3               0          0  \n",
       "4               0          0  \n",
       "...           ...        ...  \n",
       "299995          0          0  \n",
       "299996          0          0  \n",
       "299997          0          0  \n",
       "299998          0          0  \n",
       "299999          0          0  \n",
       "\n",
       "[300000 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bin_0_0.0</th>\n      <th>bin_0_1.0</th>\n      <th>bin_1_0.0</th>\n      <th>bin_1_1.0</th>\n      <th>bin_2_0.0</th>\n      <th>bin_2_1.0</th>\n      <th>bin_3_1.0</th>\n      <th>bin_3_0.0</th>\n      <th>bin_4_1.0</th>\n      <th>bin_4_0.0</th>\n      <th>...</th>\n      <th>month_0.0</th>\n      <th>month_3.0</th>\n      <th>month_9.0</th>\n      <th>month_2.0</th>\n      <th>month_6.0</th>\n      <th>month_8.0</th>\n      <th>month_11.0</th>\n      <th>month_10.0</th>\n      <th>month_4.0</th>\n      <th>month_5.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "map_info = deepcopy(encoder.category_mapping)\n",
    "[_dict_.update({\"len\" : len(_dict_[\"mapping\"])-1}) for _dict_ in map_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import gumbel_softmax as g_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit2onehot(logit, map_info) :\n",
    "    cur_position = 0\n",
    "    result = []\n",
    "    for col_info in map_info :\n",
    "        cur_position += col_info[\"len\"]\n",
    "        tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "        onehot_ = g_softmax(logits= tt , hard=True,tau=1)\n",
    "        result.append(onehot_)\n",
    "    return torch.cat(result,axis=1)\n",
    "\n",
    "from torch.distributions import Categorical\n",
    "def logit2dist(logit,map_info) :\n",
    "    cur_position = 0\n",
    "    result = []\n",
    "    for col_info in map_info :\n",
    "        cur_position += col_info[\"len\"]\n",
    "        tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "        dist = Categorical(logits = tt)\n",
    "        result.append(dist)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['bin_0_0.0',\n",
       " 'bin_0_1.0',\n",
       " 'bin_1_0.0',\n",
       " 'bin_1_1.0',\n",
       " 'bin_2_0.0',\n",
       " 'bin_2_1.0',\n",
       " 'bin_3_1.0',\n",
       " 'bin_3_0.0',\n",
       " 'bin_4_1.0',\n",
       " 'bin_4_0.0',\n",
       " 'month_1.0',\n",
       " 'month_7.0',\n",
       " 'month_0.0',\n",
       " 'month_3.0',\n",
       " 'month_9.0',\n",
       " 'month_2.0',\n",
       " 'month_6.0',\n",
       " 'month_8.0',\n",
       " 'month_11.0',\n",
       " 'month_10.0',\n",
       " 'month_4.0',\n",
       " 'month_5.0']"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "total_column = df_trans.columns.tolist()\n",
    "total_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataclasses import dataclass, field\n",
    "# @dataclass\n",
    "# class Book :\n",
    "#     n_d: int\n",
    "#     n_a: int = 8\n",
    "#     n_steps: int = 3\n",
    "\n",
    "#     def __post_init__(self,data) :\n",
    "#         self.full = self.n_d + self.n_a\n",
    "# Book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataModule(pl.LightningDataModule) :\n",
    "    def __init__(self, data , batch_size:int = 32 , num_workers:int=3) :\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.dims = self.data.shape[1]\n",
    "    \n",
    "    def prepare_data(self,) :\n",
    "        pass\n",
    "\n",
    "    def setup(self,stage=None) :\n",
    "        if stage == \"fit\" or state is None :\n",
    "            train_length = int(len(self.data)*0.8)\n",
    "            lengths = [train_length, int(len(self.data)-train_length)]\n",
    "            self.train, self.val = random_split(self.data, lengths)\n",
    "        \n",
    "        if stage == \"test\" or stage is None :\n",
    "            self.test = self.data   \n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train , batch_size= self.batch_size , num_workers=self.num_workers )\n",
    "\n",
    "    def valid_dataloader(self):\n",
    "        return DataLoader(self.val , batch_size= self.batch_size , num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test , batch_size= self.batch_size , num_workers=self.num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, out_shape, map_info , encoder, total_column):\n",
    "        super().__init__()\n",
    "        self.out_shape = out_shape\n",
    "        self.map_info = map_info\n",
    "        self.encoder = encoder\n",
    "        self.total_column = total_column\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=True),\n",
    "            *block(128, 128, normalize=True),\n",
    "            *block(128, 64, normalize=True),\n",
    "            *block(64, 32, normalize=True),\n",
    "            nn.Linear(32, self.out_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.model(z)\n",
    "        # img = img.view(img.size(0), *self.out_shape)\n",
    "        return x\n",
    "\n",
    "    def inference(self,z) :\n",
    "        x = self.model(z)\n",
    "        x = self.logit2onehot(x)\n",
    "        return self.onehot2rev(x)\n",
    "\n",
    "    def inference_tabnet_training(self,z):\n",
    "        return torch.FloatTensor(self.inference(z).values)\n",
    "\n",
    "    def splitbycolumn(self,logit) :\n",
    "        cur_position = 0\n",
    "        result = []\n",
    "        for col_info in self.map_info :\n",
    "            cur_position += col_info[\"len\"]\n",
    "            tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "            result.append(tt)\n",
    "        return result\n",
    "\n",
    "    def logit2index(self,logit) :\n",
    "        cur_position = 0\n",
    "        result = []\n",
    "        for col_info in self.map_info :\n",
    "            cur_position += col_info[\"len\"]\n",
    "            tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "            onehot_ = g_softmax(logits= tt , hard=True,tau=1)\n",
    "            result.append(torch.argmax(tt,axis=1))\n",
    "        return result\n",
    "\n",
    "    def logit2onehot(self,logit) :\n",
    "        cur_position = 0\n",
    "        result = []\n",
    "        for col_info in self.map_info :\n",
    "            cur_position += col_info[\"len\"]\n",
    "            tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "            onehot_ = g_softmax(logits= tt , hard=True,tau=1)\n",
    "            result.append(onehot_)\n",
    "        return torch.cat(result,axis=1)\n",
    "    \n",
    "    def logit2dist(self,logit) :\n",
    "        cur_position = 0\n",
    "        result = []\n",
    "        for col_info in self.map_info :\n",
    "            cur_position += col_info[\"len\"]\n",
    "            tt = logit[:, (cur_position-col_info[\"len\"]):cur_position]\n",
    "            dist = Categorical(logits = tt)\n",
    "            result.append(dist)\n",
    "        return result\n",
    "\n",
    "    def onehot2rev(self,tensor) :\n",
    "        gene_onehot_pd = pd.DataFrame(tensor.detach().numpy(),\n",
    "        columns=self.total_column)\n",
    "        gene_data = self.encoder.inverse_transform(gene_onehot_pd)\n",
    "        return gene_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim=30, out_shape=len(total_column),\n",
    "map_info=map_info,encoder=encoder , total_column=total_column)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    bin_0  bin_1  bin_2  bin_3  bin_4  month\n",
       "0       1      1      1      0      1      8\n",
       "1       1      1      1      0      0      4\n",
       "2       1      1      1      0      0     10\n",
       "3       0      1      1      0      0     10\n",
       "4       1      0      1      0      0      3\n",
       "..    ...    ...    ...    ...    ...    ...\n",
       "95      0      1      1      1      0      4\n",
       "96      0      1      0      0      0      1\n",
       "97      0      0      0      1      0      9\n",
       "98      0      1      0      0      0     11\n",
       "99      0      0      0      1      1      9\n",
       "\n",
       "[100 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "z = torch.randn(100, 30)\n",
    "gene_logit = generator(z)\n",
    "gene_onehot_tensor = logit2onehot(gene_logit, map_info)\n",
    "gene_onehot_pd = pd.DataFrame(gene_onehot_tensor.detach().numpy(),columns=total_column)\n",
    "gene_data = encoder.inverse_transform(gene_onehot_pd)\n",
    "gene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(100, 30)\n",
    "# generator.inference(z)\n",
    "# generator.splitbycolumn(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor(0.6931, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6849, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6899, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6918, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6870, grad_fn=<MeanBackward0>),\n",
       " tensor(2.4803, grad_fn=<MeanBackward0>)]"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "[dist.entropy().mean() for dist in logit2dist(gene_logit , map_info)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "Discriminator = partial(TabNet, \n",
    "            output_dim = 1,\n",
    "            n_d=n_d,\n",
    "            n_a=n_a,\n",
    "            n_steps=n_steps,\n",
    "            gamma=gamma,\n",
    "            cat_idxs=cat_idxs,\n",
    "            cat_dims=cat_dims,\n",
    "            cat_emb_dim=cat_emb_dim,\n",
    "            n_independent=n_independent,\n",
    "            n_shared=n_shared,\n",
    "            epsilon=epsilon,\n",
    "            virtual_batch_size=virtual_batch_size,\n",
    "            momentum=momentum,\n",
    "            mask_type=mask_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disc = Discriminator(dm.size())\n",
    "# disc(torch.FloatTensor(generator.inference(z).values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule): \n",
    "    def __init__(self,\n",
    "                gene_output_dim = None,\n",
    "                disc_input_dim = None,\n",
    "                latent_dim =100 , \n",
    "                lr: float = 0.0002,\n",
    "                b1: float = 0.5,\n",
    "                b2: float = 0.999,\n",
    "                generator_parm:dict={},\n",
    "                discriminator_parm:dict={},\n",
    "                # batch_size: int = 64,\n",
    "                **kwargs) :\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim,\n",
    "        out_shape=self.hparams.gene_output_dim,**generator_parm)\n",
    "\n",
    "        self.discriminator = Discriminator(input_dim=self.hparams.disc_input_dim,**discriminator_parm)\n",
    "\n",
    "        self.validation_z = torch.randn(8, self.hparams.latent_dim)\n",
    "\n",
    "        self.example_input_array = torch.zeros(2, self.hparams.latent_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "    \n",
    "    def inference(self,z) :\n",
    "        return self.generator.inference(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch\n",
    "        z = torch.randn(x.shape[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(x)\n",
    "        generated_x = self.generator.inference_tabnet_training(z)\n",
    "        valid = torch.ones(x.size(0), 1)\n",
    "        valid = valid.type_as(x)\n",
    "        logit,M_loss = self.discriminator(generated_x)\n",
    "        reward = F.binary_cross_entropy(nn.Sigmoid()(logit), valid,reduction ='mean').detach()\n",
    "        self.log('val_reward', reward)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        x = batch\n",
    "        # sample noise\n",
    "        z = torch.randn(x.shape[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(x)\n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "            ## TODO: how to training generator? \n",
    "            ## TODO: 현재 강화학습 방식을 도입하여 유사한 로스를 설계해서 진행중...(어디에도 없는 방식이라 확신 없음)\n",
    "            \n",
    "            # generate images\n",
    "            self.generated_imgs = self.generator.inference_tabnet_training(z)\n",
    "\n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            valid = torch.ones(x.size(0), 1)\n",
    "            valid = valid.type_as(x)\n",
    "\n",
    "            # adversarial loss is binary cross-entropy\n",
    "            logit,M_loss = self.discriminator(self.generated_imgs)\n",
    "            # g_loss = self.adversarial_loss(nn.Sigmoid()(logit), valid).detach()\n",
    "            reward = 1/F.binary_cross_entropy(nn.Sigmoid()(logit), valid,reduction ='none').detach()\n",
    "            logit = self.generator(z)\n",
    "            list_of_dist = self.generator.logit2dist(logit)\n",
    "            list_of_action = self.generator.logit2index(logit)\n",
    "            g_loss_list = [(dist.log_prob(action) * reward.squeeze()).mean() for dist , action in zip(list_of_dist,list_of_action)]\n",
    "            # print(g_loss)\n",
    "            g_loss = torch.stack(g_loss_list).mean()\n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': g_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(x.size(0), 1)\n",
    "            valid = valid.type_as(x)\n",
    "            logit,M_loss = self.discriminator(x)\n",
    "            real_loss = self.adversarial_loss(nn.Sigmoid()(logit), valid)\n",
    "\n",
    "            # how well can it label as fake?\n",
    "            fake = torch.zeros(x.size(0), 1)\n",
    "            fake = fake.type_as(x)\n",
    "            logit,M_loss =self.discriminator(self.generator.inference_tabnet_training(z).detach())\n",
    "            fake_loss = self.adversarial_loss(nn.Sigmoid()(logit) , fake)\n",
    "\n",
    "            # discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        z = self.validation_z.type_as(self.generator.model[0].weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_parm = dict(map_info=map_info,encoder=encoder,total_column = total_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TabularDataModule(df.values.astype(np.float32),batch_size=1024)\n",
    "model = GAN(gene_output_dim = len(total_column), disc_input_dim = dm.size(), generator_parm = generator_parm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name          | Type      | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------\n",
      "0 | generator     | Generator | 41.2 K | [2, 100] | [2, 22]  \n",
      "1 | discriminator | TabNet    | 4.4 K  | ?        | ?        \n",
      "-------------------------------------------------------------------\n",
      "45.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "45.6 K    Total params\n",
      "0.182     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1eeb9a171eae449590a77bb669528abd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1239dcabb2ab4fac8773cfdb8328f44d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = pl.Trainer(gpus=0, max_epochs=10, progress_bar_refresh_rate=20)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"./cat_gan_model.ckpt\")\n",
    "new_model = model.load_from_checkpoint(checkpoint_path=\"./cat_gan_model.ckpt\")\n",
    "trainer = pl.Trainer(gpus=0, max_epochs=100, progress_bar_refresh_rate=20)\n",
    "trainer.fit(new_model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Checkpoint directory ./model exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/opt/conda/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name          | Type      | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------\n",
      "0 | generator     | Generator | 41.2 K | [2, 100] | [2, 22]  \n",
      "1 | discriminator | TabNet    | 4.4 K  | ?        | ?        \n",
      "-------------------------------------------------------------------\n",
      "45.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "45.6 K    Total params\n",
      "0.182     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4723019b29104847aef97ceb654665cd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d19dd61d03af4248b8a088b08df75a20"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 0, global step 234: val_reward was not in top 1\n",
      "Epoch 1, global step 469: val_reward was not in top 1\n",
      "/opt/conda/envs/test/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "new_model = model.load_from_checkpoint(checkpoint_path=\"./cat_gan_model.ckpt\")\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint , EarlyStopping\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_reward',\n",
    "    dirpath='./model',\n",
    "    verbose=True,\n",
    "    filename='gan-{epoch:02d}-{val_reward:.2f}',\n",
    "    save_top_k=1, # 3,\n",
    "    # save_last=True,\n",
    "    mode='min',\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_reward',\n",
    "    patience=100,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=0, max_epochs=100, progress_bar_refresh_rate=20,callbacks=[checkpoint_callback,early_stopping])\n",
    "trainer.fit(new_model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   bin_0  bin_1  bin_2 bin_3 bin_4  month\n",
       "0      0      0      1     F     Y      9\n",
       "1      0      0      1     F     N      7\n",
       "2      1      0      0     F     Y      8\n",
       "3      0      0      1     F     Y      9\n",
       "4      0      0      1     T     N      9\n",
       "5      1      0      0     F     Y      2\n",
       "6      0      0      0     T     Y      1\n",
       "7      0      0      1     F     Y      8\n",
       "8      1      0      1     T     Y      8\n",
       "9      0      0      1     T     N      5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>F</td>\n      <td>N</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>T</td>\n      <td>N</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>T</td>\n      <td>N</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "z = torch.randn(10, model.hparams.latent_dim)\n",
    "model.inference(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}